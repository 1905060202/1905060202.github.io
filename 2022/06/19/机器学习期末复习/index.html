<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>机器学习期末复习 | 胡小宁的博客</title><meta name="keywords" content="八股文,期末复习,机器学习"><meta name="author" content="胡小宁"><meta name="copyright" content="胡小宁"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习期末题型一、考试题型：  名词解释：4 * 5’ （回归分析，马尔科夫，预剪枝）-必拿分 20分 简答题：5 * 10’ （决策树条件，常见的聚类方法、卷积神经网络的计算）-拿35+分 35+分 算法改进题：15’（加惩罚项，正则项，损失函数）5+分 问答题：15’（机器学习应用于生活）-必拿分 15分  争取拿75+分 二、重点：  机器学习的应用    监督学习（分类，回归），无监督学">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习期末复习">
<meta property="og:url" content="http://1905060202.github.io/2022/06/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/index.html">
<meta property="og:site_name" content="胡小宁的博客">
<meta property="og:description" content="机器学习期末题型一、考试题型：  名词解释：4 * 5’ （回归分析，马尔科夫，预剪枝）-必拿分 20分 简答题：5 * 10’ （决策树条件，常见的聚类方法、卷积神经网络的计算）-拿35+分 35+分 算法改进题：15’（加惩罚项，正则项，损失函数）5+分 问答题：15’（机器学习应用于生活）-必拿分 15分  争取拿75+分 二、重点：  机器学习的应用    监督学习（分类，回归），无监督学">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2022-06-19T10:13:16.000Z">
<meta property="article:modified_time" content="2022-06-26T08:52:25.078Z">
<meta property="article:author" content="胡小宁">
<meta property="article:tag" content="八股文">
<meta property="article:tag" content="期末复习">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/images/you.jpg"><link rel="canonical" href="http://1905060202.github.io/2022/06/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习期末复习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-26 16:52:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/you.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">81</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">胡小宁的博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习期末复习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-19T10:13:16.000Z" title="发表于 2022-06-19 18:13:16">2022-06-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-06-26T08:52:25.078Z" title="更新于 2022-06-26 16:52:25">2022-06-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习期末复习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="机器学习期末题型"><a href="#机器学习期末题型" class="headerlink" title="机器学习期末题型"></a>机器学习期末题型</h1><p>一、考试题型：</p>
<ol>
<li>名词解释：4 * 5’ （回归分析，马尔科夫，预剪枝）-必拿分 <strong>20分</strong></li>
<li>简答题：5 * 10’ （决策树条件，常见的聚类方法、卷积神经网络的计算）-拿35+分 <strong>35+分</strong></li>
<li>算法改进题：15’（加惩罚项，正则项，损失函数）<strong>5+分</strong></li>
<li>问答题：15’（机器学习应用于生活）-必拿分 <strong>15分</strong></li>
</ol>
<p><strong>争取拿75+分</strong></p>
<p>二、重点：</p>
<ul>
<li><p><strong>机器学习的应用</strong></p>
</li>
<li><p><input checked="" disabled="" type="checkbox">  监督学习（分类，回归），无监督学习（聚类，降维），强化学习，深度学习</p>
</li>
<li><p><input checked="" disabled="" type="checkbox">  过拟合，欠拟合，泛化</p>
</li>
<li><p><strong>评估方法：留出法，交叉验证法，自助法（重点）</strong></p>
</li>
<li><p><strong>线性回归：公式</strong></p>
<pre><code>**最小二乘法（改进：加正则项（岭回归，套索回归））**</code></pre>
</li>
</ul>
<p><strong>必考：</strong></p>
<ul>
<li><p><input checked="" disabled="" type="checkbox">  决策树算法：ID3，C4.5，CART，RF（目前最好）</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox">  决策树判断条件</p>
</li>
<li><p><input checked="" disabled="" type="checkbox">  信息增益，信息增益率，基尼系数 </p>
</li>
</ul>
</li>
<li><p><input checked="" disabled="" type="checkbox">  HMM能解决的问题 </p>
</li>
<li><p><input checked="" disabled="" type="checkbox">  卷积神经网络的计算：</p>
</li>
</ul>
<p>​            <strong>梯度消失，梯度爆炸</strong></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 常见聚类方法：<pre><code> 原型模型：K均值聚类
 密度模型：DBSCAN
 层次模型：AGNES</code></pre>
</li>
</ul>
<h1 id="机器学习期末复习"><a href="#机器学习期末复习" class="headerlink" title="机器学习期末复习"></a>机器学习期末复习</h1><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><h3 id="回归分析（重点）"><a href="#回归分析（重点）" class="headerlink" title="回归分析（重点）"></a>回归分析（重点）</h3><ul>
<li>回归分析是处理多变量间相关关系的一种数学方法</li>
<li>回归分析可以解决以下问题：<ul>
<li>建立变量间的数学表达式</li>
<li>利用概率统计基础知识进行分析</li>
<li>进行因素分析</li>
</ul>
</li>
<li>回归分析步骤：<ul>
<li>确定进行预测的因变量</li>
<li>集中说明变量，进行多元回归分析</li>
</ul>
</li>
<li>回归分析可以分为：<ul>
<li>线性回归分析</li>
<li>逻辑回归分析</li>
</ul>
</li>
</ul>
<h3 id="马尔可夫性（重点）"><a href="#马尔可夫性（重点）" class="headerlink" title="马尔可夫性（重点）"></a>马尔可夫性（重点）</h3><p>如果一个过程的“将来”，仅依赖“现在”而不依赖“过去”，则此过程具有马尔科夫性，或称此过程为马尔可夫模型。</p>
<h3 id="预剪枝（重点）"><a href="#预剪枝（重点）" class="headerlink" title="预剪枝（重点）"></a>预剪枝（重点）</h3><p>是剪枝方法中的一种策略。为了对付“过拟合”情况，提前终止某些分支的生长，称为预剪枝策略。</p>
<h3 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h3><ul>
<li>欠拟合：是指模型不能在训练集上获得足够低的误差。换句话说，就是模型复杂度过低，模型在训练集上就表现很差，没法学习到数据背后的过滤。<ul>
<li>解决方法：通过增加网络复杂度或者在模型中增加特征</li>
</ul>
</li>
<li>过拟合：是指训练误差和测试误差之间差距很大。换句话说，就是模型复杂度高于实际问题，模型在训练集上表现很好，但是在测试集中表现却很差<ul>
<li>解决方法：使用正则化方法</li>
</ul>
</li>
</ul>
<h3 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h3><p>泛化能力是指一个机器学习算法对于没有见过的样本的识别能力。</p>
<h2 id="简答题"><a href="#简答题" class="headerlink" title="简答题"></a>简答题</h2><h3 id="机器学习的一些概念"><a href="#机器学习的一些概念" class="headerlink" title="机器学习的一些概念"></a>机器学习的一些概念</h3><h4 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h4><p>机器学习的主要任务：</p>
<ul>
<li>分类：将实例数据划分到合适的类别中</li>
<li>回归：主要用于预测数值型数据</li>
</ul>
<p>机器学习可以分为三种形式：</p>
<ul>
<li>监督学习</li>
<li>非监督学习</li>
<li>强化学习</li>
</ul>
<h4 id="监督学习、无监督学习、强化学习与深度学习区别"><a href="#监督学习、无监督学习、强化学习与深度学习区别" class="headerlink" title="监督学习、无监督学习、强化学习与深度学习区别"></a>监督学习、无监督学习、强化学习与深度学习区别</h4><ul>
<li>监督学习：必须确定目标变量的值，以便机器学习算法可以发现特征和目标变量之间的关系。<ul>
<li>监督学习包括：<ul>
<li>分类</li>
<li>回归</li>
</ul>
</li>
</ul>
</li>
<li>无监督学习：在未加标签的数据中，试图找到隐藏的结构。数据没有类别信息，也没有给定的目标值。<ul>
<li>无监督学习包括的类型：<ul>
<li>聚类：将数据集分成由类似的对象组成多个类</li>
<li>密度估计：通过样本分布的紧密程度，来估计与分组的相似性</li>
<li>降维</li>
</ul>
</li>
</ul>
</li>
<li>强化学习：智能系统从环境到行为映射的学习，以使强化信号函数值最大。<ul>
<li>最关键的三个因素：<ul>
<li>状态</li>
<li>行为</li>
<li>环境奖励</li>
</ul>
</li>
</ul>
</li>
<li>深度学习：DNN可以将原始信号直接作为输入值，而不需要创建任何的输入特征。通过多层神经元，DNN可以自动在每一层产生适当的特征，最后提供一个非常好的预测，极大消除了寻找“特征工程”的麻烦。<ul>
<li>DNN演变的网络拓扑结构：<ul>
<li>CNN(卷积神经网络)</li>
<li>RNN(递归神经网络)</li>
<li>LSTM(长期短期记忆网络)</li>
<li>GAN(生成对抗网络)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="评估方法（重点）"><a href="#评估方法（重点）" class="headerlink" title="评估方法（重点）"></a>评估方法（重点）</h3><ul>
<li>留出法：将数据集换分为两个互斥部分，一部分作为训练集，一部分作为测试集。通常训练集和测试集比例为70%：30%。</li>
<li>交叉验证法：将数据集换分为k个大小相似的互斥子集，每次采用k-1个子集的并集作为训练集，剩下的那个子集作为测试集。进行k次训练和测试，最总返回k个测试结果的均值。</li>
<li>自助法：以自主采样为基础，每次随机从数据集D(样本数m个)中挑选一个样本，放入D’中，然后将样本放回D中，重复m次后，得到了包含m个样本的数据集。</li>
</ul>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><h4 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h4><ul>
<li>第一个决策树算法：CLS</li>
<li>使决策树受到关注、成为机器学习主流技术的的算法：ID3</li>
<li>最常用的决策树算法：C4.5</li>
<li>可用于回归任务的决策树算法：CART</li>
<li>基于决策树的强大算法：RF</li>
</ul>
<h4 id="决策树的三种停止条件是什么？（重点）"><a href="#决策树的三种停止条件是什么？（重点）" class="headerlink" title="决策树的三种停止条件是什么？（重点）"></a>决策树的三种停止条件是什么？（重点）</h4><ul>
<li>当前节点包含的样本全属于同一类别，无需划分</li>
<li>当前属性集为空，或是所有样本在属性集上取值相同，无法划分</li>
<li>当前节点包含的样本集合为空，不能划分</li>
</ul>
<h4 id="信息增益，信息增益率，基尼系数？"><a href="#信息增益，信息增益率，基尼系数？" class="headerlink" title="信息增益，信息增益率，基尼系数？"></a>信息增益，信息增益率，基尼系数？</h4><p><strong>信息增益、信息增益率、基尼系数，都是用来选择划分属性的一种手段，分别被用于不同的算法之中。</strong></p>
<ul>
<li><p><strong>信息增益是用来选择划分属性的一种手段，信息增益对可取值数目较多的属性有所偏好。(ID3使用)</strong></p>
<ul>
<li>为了方便理解上面这句话，下面给出老师ppt里面的例子。</li>
<li><img src="/images/python/image-20220622214546686.png" alt="信息熵"></li>
<li><img src="/images/python/image-20220622214610245.png" alt="信息熵2"></li>
<li>例子：<ul>
<li><img src="/images/python/image-20220622214635812.png" alt="例子"></li>
<li><img src="/images/python/image-20220622214651303.png" alt="例子2"></li>
<li><img src="/images/python/image-20220622214705219.png" alt="例子3"></li>
<li><img src="/images/python/image-20220622214730508.png" alt="例子4"></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>增益率：先从候选划分属性中找出信息增益高于平均水平的，再从中选取增益率最高的。(C4.5算法使用)</strong></p>
<ul>
<li><img src="/images/python/image-20220622214524354.png" alt="增益率"></li>
</ul>
</li>
<li><p><strong>基尼系数：在侯选属性集合中，选取那个使划分后基尼系数最小的属性。(CART算法使用)</strong></p>
<ul>
<li><img src="/images/python/image-20220622215006281.png" alt="基尼系数"></li>
</ul>
</li>
</ul>
<h4 id="剪枝（重点）"><a href="#剪枝（重点）" class="headerlink" title="剪枝（重点）"></a>剪枝（重点）</h4><p><strong>剪枝的目的：</strong></p>
<ul>
<li><strong>为了尽可能正确分类训练样本，有可能造成分支过多-&gt;过拟合，可通过主动去掉一些分支来降低过拟合风险。</strong></li>
</ul>
<h5 id="剪枝的策略"><a href="#剪枝的策略" class="headerlink" title="剪枝的策略"></a>剪枝的策略</h5><ul>
<li>预剪枝：提前终止某些分支的生长</li>
<li>后剪枝：生成一颗完全树，再“回头”剪枝</li>
</ul>
<p><img src="/images/python/image-20220622221208191.png" alt="未剪枝的决策树"></p>
<p><img src="/images/python/image-20220622221420672.png" alt="预剪枝后的决策树"></p>
<p><strong>预剪枝就像一个生长的小树，随着她增长，剪掉她的枝叶。后剪枝就像一颗已经长大的参天大树，剪掉他的一些分支。</strong></p>
<h3 id="隐马尔可夫模型（重点）"><a href="#隐马尔可夫模型（重点）" class="headerlink" title="隐马尔可夫模型（重点）"></a>隐马尔可夫模型（重点）</h3><p>HMM的状态是不确定的或不可见的，只有通过观测序列的随机过程才能表现出来。</p>
<p>HMM是一个双重随机过程，两个部分组成：</p>
<ul>
<li>马尔可夫链：描述状态的转移，用转移概率描述</li>
<li>一般随机过程：描述状态与观察序列间的关系，用观察值概率描述</li>
</ul>
<h4 id="HMM可以解决的问题（重点）"><a href="#HMM可以解决的问题（重点）" class="headerlink" title="HMM可以解决的问题（重点）"></a>HMM可以解决的问题（重点）</h4><ul>
<li>评估问题：给定观察序列O=O1,O2,…OT,以及模型λ =(π，A，B), 如何计算P(O|λ)？<ul>
<li>Forward-Backward算法</li>
</ul>
</li>
<li>解码问题：给定观察序列O=O1,O2,…OT以及模型λ,如何选择一个对应的状态序列S = q1,q2,…qT，使得S能够最为合理的解释观察序列O？ <ul>
<li>Viterbi算法 </li>
</ul>
</li>
<li>学习问题：n如何调整模型参数λ =(π，A，B),对于给定观测值序列O=O1,O2,…OT，使得P(O|λ)最大？<ul>
<li>Baum-Welch算法 </li>
</ul>
</li>
</ul>
<h3 id="卷积神经网络（重点）"><a href="#卷积神经网络（重点）" class="headerlink" title="卷积神经网络（重点）"></a>卷积神经网络（重点）</h3><p>在这里贴一张神图镇楼：</p>
<p><img src="/images/python/%E7%A5%9E%E5%9B%BE.gif" alt="神图"></p>
<h4 id="卷积神经网络的计算（转载）"><a href="#卷积神经网络的计算（转载）" class="headerlink" title="卷积神经网络的计算（转载）"></a>卷积神经网络的计算（转载）</h4><h5 id="CNN结构介绍："><a href="#CNN结构介绍：" class="headerlink" title="CNN结构介绍："></a>CNN结构介绍：</h5><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jYW1wb28uY2Mvd3AtY29udGVudC91cGxvYWRzLzIwMTkvMDIvY25uLXN0cnVjdHVyZS5wbmc?x-oss-process=image/format,png" alt="CNN结构介绍"></p>
<p>上面是一个简单的CNN结构图，第一层输入图片，进行卷积(Convolution)操作，的到第二层深度为3的特征图(Feature Map).对第二层的特征图进行池化(Pooling)操作，得到第三层深度为3的特征图。重复上述操作得到第五层深度为5的特征图，最后将这5个特征图，也就是5个矩阵，按行展开连接成向量，传入全连接层(Fully Connected)，全连接层就是一个BP神经网络。图中的每个特征图都可以看成是排列成矩阵形式的神经元，与BP神经网络中的神经元大同小异。下面是卷积和池化的计算过程：</p>
<h5 id="卷积："><a href="#卷积：" class="headerlink" title="卷积："></a><strong>卷积：</strong></h5><p>对于一张输入图片, 将其转化为矩阵, 矩阵的元素为对应的像素值.假设有一个5×5的图像，使用一个3×3的卷积核进行卷积，可得到一个3×3的特征图，卷积核也成为滤波器(Filter).</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jYW1wb28uY2Mvd3AtY29udGVudC91cGxvYWRzLzIwMTkvMDIvY25uLWZpbHRlci0xLnBuZw?x-oss-process=image/format,png" alt="图像使用卷积核进行卷积"></p>
<p>具体的操作过程如下：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9sYWIuY2FtcG9vLmNjL3NpbXBsZW1kL1R5cG9yYS9hc3NldHMvY25uLWNvbnYtMTU3ODM1NTM4ODc5MS5naWY#pic_center" alt="动态卷积操作图"></p>
<p>黄色的区域表示卷积核在输入矩阵中滑动，每滑动到一个位置，将位置数字相乘并求和，得到一个特征图矩阵的元素。注意到，动图中卷积核每次滑动了一个单位，实际上滑动的幅度可以根据需要进行调整。如果滑动步幅大于1，则卷积核有可能无法恰好滑倒边缘，针对这种情况，可在矩阵最外层补零。</p>
<p><img src="https://img-blog.csdnimg.cn/20200109232014126.png" alt="在这里插入图片描述"></p>
<p>上图是对一个特征图采用一个卷积核卷积的过程，为了提取更多的特征，可以采用多个卷积核分别进行卷积，这样便可以得到多个特征。有时，对于一张三通道彩色图片，或者如第三层特征图所示每输入的是一组矩阵，这时卷积核也不再是一层的，而要变成相应的深度。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jYW1wb28uY2Mvd3AtY29udGVudC91cGxvYWRzLzIwMTkvMDIvY25uLWNvbnYtMC5naWY" alt="多卷积核"></p>
<p>上图中，最左边是输入特征图的矩阵，深度为3，补零层数为1，每次滑动的步幅为2.中间两列粉色的矩阵分别是两组卷积核，一组有三个，三个矩阵分别对应着卷积左侧三个输入矩阵，每一次滑动卷积会得到三个数，这三个数的和作为卷积的输出。最右侧两个绿色矩阵分别是两组卷积核得到的特征图。</p>
<h5 id="池化："><a href="#池化：" class="headerlink" title="池化："></a><strong>池化：</strong></h5><p>池化又叫下采样(Down sampling)，与之相对的是上采样(Up sampling)。卷积得到的特征图一般需要一个池化层以降低数据量。池化的操作如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200109232036372.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXBmOA==,size_16,color_FFFFFF,t_70" alt="池化操作"></p>
<p>和卷积一样，池化也有一个滑动的核，可以称之为滑动窗口，上图中滑动窗口的大小为2×2，步幅为2，每滑动到一个区域，则取最大值作为输出，这样的操作成为Max Pooling。还可以采用输出均值的方式，成为Mean Pooling。</p>
<h5 id="全连接："><a href="#全连接：" class="headerlink" title="全连接："></a>全连接：</h5><p>经过若干层的卷积，池化操作后，将得到的特征图依次按行展开，连接成向量，输入全连接网络。</p>
<p>更多的计算与操作，请看原文。这里不再赘述，考试不会考到这么复杂的计算。</p>
<p>————————————————<br>版权声明：本文为CSDN博主「天在那边」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weipf8/article/details/103917202">https://blog.csdn.net/weipf8/article/details/103917202</a></p>
<p>————————————————</p>
<h4 id="梯度爆炸和梯度消失"><a href="#梯度爆炸和梯度消失" class="headerlink" title="梯度爆炸和梯度消失"></a>梯度爆炸和梯度消失</h4><ul>
<li>梯度消失：靠后面的网络层能正常的得到一个合理的偏导数，但是靠近输入层的网络层，计算得到的偏导数几乎为零，W几乎无法得到更新</li>
<li>梯度爆炸：靠近输入层的网络层，计算得到的偏导数极大，更新后W变成一个很大的数</li>
</ul>
<h3 id="常见的聚类方法（重点）"><a href="#常见的聚类方法（重点）" class="headerlink" title="常见的聚类方法（重点）"></a>常见的聚类方法（重点）</h3><ul>
<li><p>原型聚类：</p>
<ul>
<li>假设：聚类结构能够通过一组原型刻画</li>
<li>过程：先对原型初始化，然后对原型进行迭代更新求解</li>
<li>代表：**k均值聚类(k-means)**，高斯混合聚类</li>
</ul>
</li>
<li><p>密度聚类：</p>
<ul>
<li><p>假设：聚类结构能够通过样本分布的紧密程度确定</p>
</li>
<li><p>过程：从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇</p>
</li>
<li><p>DBSCAN，OPTICS</p>
</li>
</ul>
</li>
<li><p>层次聚类：</p>
<ul>
<li>假设：能够产生不同粒度的聚类结果</li>
<li>过程：在不同层次对数据集进行划分，从而形成树形的聚类结构。</li>
<li>代表：AGNES（自底向上），DIANA（自顶向下）</li>
</ul>
</li>
</ul>
<h2 id="算法改进题目（押题，考了能拿满分）（次重点）"><a href="#算法改进题目（押题，考了能拿满分）（次重点）" class="headerlink" title="算法改进题目（押题，考了能拿满分）（次重点）"></a>算法改进题目（押题，考了能拿满分）（次重点）</h2><h3 id="线性回归公式"><a href="#线性回归公式" class="headerlink" title="线性回归公式"></a>线性回归公式</h3><p>Y = a + bx(一元线性回归）<br>Y = a + b1x +b2x + b3+(多元线性回归）</p>
<h3 id="线性回归改进算法"><a href="#线性回归改进算法" class="headerlink" title="线性回归改进算法"></a>线性回归改进算法</h3><p>在多元线性回归中，多个变量之间可能存在多重共线性，所谓多重，就是一个变量与多个变量之间存在线性相关。首先来看下多重共线性对回归模型的影响，假设一下回归模型：</p>
<blockquote>
<p>y = 2 * x1 + 3 * x2 + 4</p>
</blockquote>
<p>举一个极端的例子，比如x1和x2 这两个变量完全线性相关，x2=2*x1, 此时，上述回归方程的前两项可以看做是2个x1和3个x2的组合，通过x1和x2的换算关系，这个组合其实可以包括多种情况，可以看看做是8个x1, 4个x2, 也可以看做是4个x1和2个x2的组合，当然还有更多的情况。</p>
<blockquote>
<p>y = 8 * x1 +4</p>
<p>y = 3 * x1 + 2 * x2 + 4 </p>
<p>y = x1 + 3.5 * x2 + 4 </p>
<p>y = 4 * x1 + 2 * x2 +4 </p>
<p>y = 4 * x2 + 4</p>
</blockquote>
<p>在x1和x2完全线性相关的情况下，以上方程都是等价的，在这里举这个完全线性相关的例子，只是为了方便理解当变量间存在线性相关时，对应的系数会相互抵消。此时，回归方程的系数难以准确估计。</p>
<p>在最小二乘法的求解过程涉及逆矩阵运算，一个矩阵可逆需要符合行列式不为零或者矩阵满秩，当变量存在多重共线性时，对应的矩阵不满秩，就会导致无法进行逆矩阵运算，也会对简单最小二乘法造成影响，尽管仍然可以通过伪逆矩阵运算来求解。</p>
<p>对于多重共线性的情况，如果执意用最小二乘法来求解，会发现，随着变量相关性的增强，回归系数的方差会变大，用一个示例的例子来验证一下，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>x = np.arange(<span class="hljs-number">0.6</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.05</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>beta1 = []<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x:<br><span class="hljs-meta">... </span>data = np.array([[i, <span class="hljs-number">2</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">8</span>]])<br><span class="hljs-meta">... </span>target = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><span class="hljs-meta">... </span>reg = linear_model.LinearRegression().fit(data, target)<br><span class="hljs-meta">... </span>beta1.append(reg.coef_[<span class="hljs-number">0</span>])<br>...<br><span class="hljs-meta">&gt;&gt;&gt; </span>plt.plot(x, beta1, <span class="hljs-string">&#x27;o-&#x27;</span>)<br>[&lt;matplotlib.lines.Line2D <span class="hljs-built_in">object</span> at <span class="hljs-number">0x13633580</span>&gt;]<br><span class="hljs-meta">&gt;&gt;&gt; </span>plt.show()<br></code></pre></td></tr></table></figure>
<p>输出结果如下:</p>
<p><img src="https://ask.qcloudimg.com/http-save/8128510/bx969y89qe.png?imageView2/2/w/1620" alt="输出结果"></p>
<p>x轴是自变量的取值，x不断增大，上述拟合结果中的自变量之间的相关系数也不断增强，可以看到，随着相关性的增强，回归系数的变化速率越来越快。而对于两个完全独立的变量而言，而拟合结果是恒定不变的，方差为0，而多重共线性则导致拟合结果随着相关系数的变化而变化，回归系数的方差变大了。</p>
<p><strong>为了解决多重共线性对拟合结果的影响，也就是平衡残差和回归系数方差两个因素，科学家考虑在损失函数中引入正则化项。所谓正则化Regularization, 指的是在损失函数后面添加一个约束项</strong>， 在线性回归模型中，有两种不同的正则化项：</p>
<ul>
<li>所有系数绝对值之和，即L1范数，对应的回归方法叫做Lasson回归，套索回归</li>
<li>所有系数的平方和，即L2范数，对应的回归方法叫做Ridge回归，岭回归</li>
</ul>
<p>岭回归对应的代价函数如下：</p>
<p><img src="https://ask.qcloudimg.com/http-save/8128510/fe20kafuxn.png?imageView2/2/w/1620" alt="岭回归对应的代价函数"></p>
<p>套索回归对应的代价函数如下：</p>
<p><img src="https://ask.qcloudimg.com/http-save/8128510/geziwnd0ym.png?imageView2/2/w/1620" alt="套索回归对应的代价函数"></p>
<p>从上面公式可以看出，两种回归方法共性，第一项就是最小二乘法的损失函数，残差平方和，各自独特的第二项就是正则化项，参数λ称之为学习率。</p>
<p>对于岭回归而言，可以直接对损失函数进行求导，在导数为0处即为最小值，直接利用矩阵运算就可以求解回归系数。</p>
<p><img src="https://ask.qcloudimg.com/http-save/8128510/pwsdly32pt.png?imageView2/2/w/1620" alt="岭回归"></p>
<p>对于套索回归而言，损失函数在w=0处不可导，所以没法直接求解，只能采用近似法求解。在scikit-learn中，有对应的API可以执行岭回归和套索回归。</p>
<h4 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h4><p>岭回归：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>data = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>data<br>array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>target = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>]).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>target<br>array([[<span class="hljs-number">0.</span> ],<br>       [<span class="hljs-number">0.1</span>],<br>       [<span class="hljs-number">1.</span> ]])<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> linear_model<br><span class="hljs-comment"># 岭回归</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>reg = linear_model.Ridge(alpha=<span class="hljs-number">.5</span>).fit(data, target)<br><span class="hljs-meta">&gt;&gt;&gt; </span>reg<br>Ridge(alpha=<span class="hljs-number">0.5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>reg.coef_<br>array([[<span class="hljs-number">0.34545455</span>, <span class="hljs-number">0.34545455</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>reg.intercept_<br>array([<span class="hljs-number">0.13636364</span>])<br></code></pre></td></tr></table></figure>
<p>套索回归：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>reg = linear_model.Lasso(alpha=<span class="hljs-number">.5</span>).fit(data, target)<br><span class="hljs-meta">&gt;&gt;&gt; </span>reg<br>Lasso(alpha=<span class="hljs-number">0.5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>reg.coef_<br>array([<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>reg.intercept_<br>array([<span class="hljs-number">0.36666667</span>])<br></code></pre></td></tr></table></figure>
<p><strong>对于存在多重共线性的病态数据，可以使用岭回归和套索回归来限制多重共线性对拟合结果的影响。</strong></p>
<p>文章转载自：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1786919">生信修炼手册</a>。</p>
<h2 id="问答题（15救命分，必拿）"><a href="#问答题（15救命分，必拿）" class="headerlink" title="问答题（15救命分，必拿）"></a>问答题（15救命分，必拿）</h2><h3 id="机器学习应用于生活（重点）"><a href="#机器学习应用于生活（重点）" class="headerlink" title="机器学习应用于生活（重点）"></a>机器学习应用于生活（重点）</h3><ul>
<li>图像识别<ul>
<li>银行手写支票识别</li>
<li>Google从Youtube视频中提取出千万张图片，让系统自动判断哪些是猫的图片</li>
<li>2016年，DeepMind的AlpahGo击败了专业围棋选手</li>
</ul>
</li>
<li>语音识别<ul>
<li>科大讯飞公司的语音识别</li>
<li>微软的语音视频检索系统</li>
</ul>
</li>
<li>自然语言处理</li>
<li>医疗保健<ul>
<li>退伍军人创伤后成长计划与IBM Watson合作使用人工智能和分析技术，以确保更多患有创伤后应激障碍反应的退伍军人能够完成心理治疗</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">胡小宁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://1905060202.github.io/2022/06/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">http://1905060202.github.io/2022/06/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://1905060202.github.io" target="_blank">胡小宁的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%85%AB%E8%82%A1%E6%96%87/">八股文</a><a class="post-meta__tags" href="/tags/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">期末复习</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/21/Spark%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E6%9C%AF%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Spark大数据分析技术期末复习</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/18/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E6%8A%80%E6%9C%AF%E6%9C%9F%E4%B8%AD%E8%80%83%E8%AF%95%E5%A4%8D%E4%B9%A0/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">软件测试技术期中考试复习</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/06/21/Spark%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E6%9C%AF%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="Spark大数据分析技术期末复习"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-21</div><div class="title">Spark大数据分析技术期末复习</div></div></a></div><div><a href="/2022/05/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%85%AB%E8%82%A1%E6%96%87/" title="大数据存储技术八股文"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-16</div><div class="title">大数据存储技术八股文</div></div></a></div><div><a href="/2022/05/18/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E6%8A%80%E6%9C%AF%E6%9C%9F%E4%B8%AD%E8%80%83%E8%AF%95%E5%A4%8D%E4%B9%A0/" title="软件测试技术期中考试复习"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-18</div><div class="title">软件测试技术期中考试复习</div></div></a></div><div><a href="/2022/09/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97/" title="操作系统面试指南"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-04</div><div class="title">操作系统面试指南</div></div></a></div><div><a href="/2021/06/30/%E7%AB%99%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%88%E7%9A%84%E8%A7%92%E5%BA%A6%E8%B0%88%E8%B0%88%E5%AF%B9%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95/" title="站在数据分析师的角度谈谈对数据的处理方法"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-30</div><div class="title">站在数据分析师的角度谈谈对数据的处理方法</div></div></a></div><div><a href="/2021/06/19/Python%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="Python与数据分析期末复习"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-19</div><div class="title">Python与数据分析期末复习</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/you.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">胡小宁</div><div class="author-info__description">虽千万人吾往矣</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">81</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/1905060202" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:xxxxxx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">前段时间博客崩溃，眼下课程设计与期末考试接踵而至，心有余而力不足，等有空再重新整理博客吧！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E9%A2%98%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">机器学习期末题型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0"><span class="toc-number">2.</span> <span class="toc-text">机器学习期末复习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A"><span class="toc-number">2.1.</span> <span class="toc-text">名词解释</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.1.1.</span> <span class="toc-text">回归分析（重点）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%80%A7%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.1.2.</span> <span class="toc-text">马尔可夫性（重点）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%89%AA%E6%9E%9D%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.1.3.</span> <span class="toc-text">预剪枝（重点）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">2.1.4.</span> <span class="toc-text">过拟合与欠拟合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B"><span class="toc-number">2.1.5.</span> <span class="toc-text">泛化能力</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E7%AD%94%E9%A2%98"><span class="toc-number">2.2.</span> <span class="toc-text">简答题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5"><span class="toc-number">2.2.1.</span> <span class="toc-text">机器学习的一些概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E3%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E3%80%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8C%BA%E5%88%AB"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">监督学习、无监督学习、强化学习与深度学习区别</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.2.</span> <span class="toc-text">评估方法（重点）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.2.3.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95"><span class="toc-number">2.2.3.1.</span> <span class="toc-text">决策树算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%B8%89%E7%A7%8D%E5%81%9C%E6%AD%A2%E6%9D%A1%E4%BB%B6%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.3.2.</span> <span class="toc-text">决策树的三种停止条件是什么？（重点）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%8C%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87%EF%BC%8C%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0%EF%BC%9F"><span class="toc-number">2.2.3.3.</span> <span class="toc-text">信息增益，信息增益率，基尼系数？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%AA%E6%9E%9D%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.3.4.</span> <span class="toc-text">剪枝（重点）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%89%AA%E6%9E%9D%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-number">2.2.3.4.1.</span> <span class="toc-text">剪枝的策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.4.</span> <span class="toc-text">隐马尔可夫模型（重点）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#HMM%E5%8F%AF%E4%BB%A5%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.4.1.</span> <span class="toc-text">HMM可以解决的问题（重点）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.5.</span> <span class="toc-text">卷积神经网络（重点）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89"><span class="toc-number">2.2.5.1.</span> <span class="toc-text">卷积神经网络的计算（转载）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#CNN%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D%EF%BC%9A"><span class="toc-number">2.2.5.1.1.</span> <span class="toc-text">CNN结构介绍：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%EF%BC%9A"><span class="toc-number">2.2.5.1.2.</span> <span class="toc-text">卷积：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96%EF%BC%9A"><span class="toc-number">2.2.5.1.3.</span> <span class="toc-text">池化：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%EF%BC%9A"><span class="toc-number">2.2.5.1.4.</span> <span class="toc-text">全连接：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E5%92%8C%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1"><span class="toc-number">2.2.5.2.</span> <span class="toc-text">梯度爆炸和梯度消失</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.2.6.</span> <span class="toc-text">常见的聚类方法（重点）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%E9%A2%98%E7%9B%AE%EF%BC%88%E6%8A%BC%E9%A2%98%EF%BC%8C%E8%80%83%E4%BA%86%E8%83%BD%E6%8B%BF%E6%BB%A1%E5%88%86%EF%BC%89%EF%BC%88%E6%AC%A1%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.3.</span> <span class="toc-text">算法改进题目（押题，考了能拿满分）（次重点）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%85%AC%E5%BC%8F"><span class="toc-number">2.3.1.</span> <span class="toc-text">线性回归公式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%94%B9%E8%BF%9B%E7%AE%97%E6%B3%95"><span class="toc-number">2.3.2.</span> <span class="toc-text">线性回归改进算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E9%83%A8%E5%88%86"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">代码部分</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E7%AD%94%E9%A2%98%EF%BC%8815%E6%95%91%E5%91%BD%E5%88%86%EF%BC%8C%E5%BF%85%E6%8B%BF%EF%BC%89"><span class="toc-number">2.4.</span> <span class="toc-text">问答题（15救命分，必拿）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E4%BA%8E%E7%94%9F%E6%B4%BB%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">2.4.1.</span> <span class="toc-text">机器学习应用于生活（重点）</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/07/Java%E9%9D%A2%E8%AF%95%E9%80%9F%E6%88%90%E6%8C%87%E5%8D%97/" title="Java面试速成指南"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java面试速成指南"/></a><div class="content"><a class="title" href="/2022/09/07/Java%E9%9D%A2%E8%AF%95%E9%80%9F%E6%88%90%E6%8C%87%E5%8D%97/" title="Java面试速成指南">Java面试速成指南</a><time datetime="2022-09-07T11:45:15.000Z" title="发表于 2022-09-07 19:45:15">2022-09-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/06/JVM%E4%B8%8EJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" title="JVM与Java并发编程"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JVM与Java并发编程"/></a><div class="content"><a class="title" href="/2022/09/06/JVM%E4%B8%8EJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" title="JVM与Java并发编程">JVM与Java并发编程</a><time datetime="2022-09-06T13:56:11.000Z" title="发表于 2022-09-06 21:56:11">2022-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/06/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/" title="系统设计与设计模式详解"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="系统设计与设计模式详解"/></a><div class="content"><a class="title" href="/2022/09/06/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/" title="系统设计与设计模式详解">系统设计与设计模式详解</a><time datetime="2022-09-06T13:54:32.000Z" title="发表于 2022-09-06 21:54:32">2022-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/06/MySQL%E8%AF%A6%E8%A7%A3/" title="MySQL详解"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL详解"/></a><div class="content"><a class="title" href="/2022/09/06/MySQL%E8%AF%A6%E8%A7%A3/" title="MySQL详解">MySQL详解</a><time datetime="2022-09-06T13:53:19.000Z" title="发表于 2022-09-06 21:53:19">2022-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/06/Redis%E8%AF%A6%E8%A7%A3/" title="Redis详解"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis详解"/></a><div class="content"><a class="title" href="/2022/09/06/Redis%E8%AF%A6%E8%A7%A3/" title="Redis详解">Redis详解</a><time datetime="2022-09-06T13:52:13.000Z" title="发表于 2022-09-06 21:52:13">2022-09-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 胡小宁</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --></body></html>